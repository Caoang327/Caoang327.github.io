<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ang Cao</title>
  
  <meta name="author" content="Ang Cao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data/image/U-M_Logo-Hex.png">

</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HN2BWBLPJG"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HN2BWBLPJG');
</script>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:1.5%;width:72%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ang Cao</name>
              </p>

              <p> I am a final-year Ph.D. student (2020-) in Computer Science and Engineering (CSE) at the University of Michigan, Ann Arbor, working with Prof.<a href="https://web.eecs.umich.edu/~justincj/"> Justin Johnson</a> and Prof.<a href="https://jjparkcv.github.io/"> JJ (Jeong Joon) Park</a>.
              I was very fortunate to work with Prof.<a href="https://andrewowens.com/"> Andrew Owens</a>.
              </p>
              <p>I work on generative model and 3D vision, especially interested in worling modeling and 3D world creation,including:
              <br>
              <b>(1) 3D/4D recontruction and generation from 2D data:</b> 
              <br>
              <a href="https://caoang327.github.io/HexPlane/">HexPlane</a>; <a href="https://caoang327.github.io/FWD/">FWD</a>; <a href="https://lightplane.github.io/">Lightplane</a>
              <br>
              <b>(2) Injecting world knowledge into 3D/4D via generative/foundation models</b> <em>(e.g., VLMs, Image/Video Diffusion Models...)</em>
              <br>
              <a href="https://lukashoel.github.io/text-to-room/">Text2Room</a>; <a href="https://liftgs.github.io/">LiftGS</a>
              <br>
              I also enjoy exloring cute ideas in generative models: <a href="https://ArXiv.org/abs/2501.00569">ViLP</a> 
        
              </p> 

              <p>
                Before that, I was a M.S. Student at UMich ECE (2018-2020)  and I did my Bachelor's degree at Wuhan University in China (2014-2018).
              </p>

              <p style="text-align:center">
                <a href="mailto:ancao@umich.edu">Email</a> &nbsp/&nbsp
                <a href="data/pdfs/cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=HtD-aVUAAAAJ&hl=zh-CN&authuser=1">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/AngCao3">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/Caoang327/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="data/image/photo.png"><img style="width:100%;max-width:100%" alt="profile photo" src="data/image/photo.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr></tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Work Experience</heading>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle; text-align:center;">
            <div class="one" style="display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100%;">
              <div class="two" id='meta_image'>
              </div>
              <img src='data/image/meta.png' width="80"> <!-- Reduced width from 100 to 80 -->
            </div>
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle; text-align:left;">
              <p>Research Scientist Intern, Meta FAIR, MPK, USA</p>
              <p> Work with <a href="https://alexsax.github.io/">Sasha Sax</a> , <a href="https://scholar.google.com/citations?user=7oxkHYYAAAAJ&hl=en">Franziska Meier</a> </p>
              <p>May 2024 - December 2024</p>

            <br>
          </td>
        </tr>
        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle; text-align:center;">
            <div class="one" style="display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100%;">
              <div class="two" id='meta_image'>
              </div>
              <img src='data/image/meta.png' width="80"> <!-- Reduced width from 100 to 80 -->
            </div>
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle; text-align:left;">
              <p>Research Scientist Intern, Meta GenAI, London, UK</p>
              <p> Work with <a href="https://d-novotny.github.io/">David Novotny</a>, <a href="https://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a> , <a href="https://scholar.google.fr/citations?user=cLPaHcIAAAAJ&hl=en">Natalia Neverova</a></p>
              <p>May 2023 - November 2023</p>

            <br>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:5px;width:100%;vertical-align:middle">
            <heading> Publications</heading> <p>Equal contribution is indicated by * </p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr onmouseout="text2roo_stop()" onmouseover="text2room_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='text2room_image'>
              </div>
              <img src='data/image/liftgs.gif' width="200">
              </div>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>From Thousands to Billions: 3D Visual Language Grounding via Render-Supervised Distillation from 2D VLMs</papertitle>
            </a>
            <br>
            <strong> Ang Cao</strong>,
            <a href="https://www.linkedin.com/in/sergio-arnaud-226456198/">Sergio Arnaud</a>, ...
            <a href="https://web.eecs.umich.edu/~justincj"> Justin Johnson</a>,
            <a href="https://jjparkcv.github.io/">JJ Park</a>,
            <a href="https://alexsax.github.io/">Alexander (Sasha) Sax
            </a>
            <br>
            <em>ICML, </em> 2025
            <br>
            <a href="https://ArXiv.org/abs/2502.20389">ArXiv</a>/
            <a href="https://liftgs.github.io/">website</a>
            <p>We (pre-)train a 3D Visual Language Grounding (3D VLG) model with only 2D supervision, by distilling languages from 2D foundation models with render-supervision.</p>
          </td>
        </tr>
      
        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='vilp_image'>
              </div>
              <img src='data/image/vilp.png' width="200">
              </div>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>Probing Visual Language Priors in VLMs</papertitle>
            </a>
            <br>
            <a href="https://tiangeluo.github.io/">Tiange Luo*</a>,
            <strong> Ang Cao*</strong>,
            <a> Gunhee Lee </a>
            <a href="https://web.eecs.umich.edu/~justincj"> Justin Johnson*</a>,
            <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee*</a>
            <br>
            <em>ICML, </em> 2025
            <a href="https://ArXiv.org/abs/2501.00569">ArXiv</a>/
            <p>How could a generator help the agent? We explore the visual language priors in VLMs by constructing novel question-image-answer triplets from image diffusion models. Proposed Image-DPO to encourage the model to use more visual inputs. </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='vilp_image'>
              </div>
              <img src='data/image/fasterteaser.png' width="200">
              </div>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass</papertitle>
            </a>
            <br>
            <a href="https://jedyang.com/">Jianing "Jed" Yang</a>,
            <a href="https://alexsax.github.io/"> Alexander Sax</a>,
            <a href="https://kevinjliang.github.io/"> Kevin J. Liang</a>,
            <a href="https://www.mikaelhenaff.net/"> Mikael Henaff</a>,
            <a href="https://tanghaotommy.github.io/"> Hao Tang</a>,
            <strong> Ang Cao</strong>,
            <a href="https://web.eecs.umich.edu/~chaijy/"> Joyce Chai</a>,
            <a href="https://fmeier.github.io/"> Franziska Meier</a>
            <a href="https://www.linkedin.com/in/matt-feiszli-76b34b/"> Matt Feiszli</a>
            <br>
            <em> CVPR, </em> 2025
            <a href="https://arxiv.org/abs/2501.13928">ArXiv</a>/
            <a href="https://fast3r-3d.github.io/">website</a>/
            <a href="https://github.com/facebookresearch/fast3r">code</a>/
            <a href="https://fast3r.ngrok.app/">Demo</a>/
            <p>We present a neat transformer-based 3D recon and camera pose est. pipeline, which can reconstruct 3D scenes from 1000+ images in one forward pass with ultra-high speed. </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='vilp_image'>
              </div>
              <img src='data/image/meta3dgen.png' width="200">
              </div>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>Meta 3D Gen</papertitle>
            </a>
            <br>
            <a>Meta GenAI 3DGen Team</a>
            <br>
            <em>Tech report, </em> 2024
            <a href="https://scontent-ord5-1.xx.fbcdn.net/v/t39.2365-6/449707112_509645168082163_2193712134508658234_n.pdf?_nc_cat=111&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=EUhEyoK5XPcQ7kNvgHkB1Nm&_nc_oc=AdkvQRgYUmrjK68KR0vS1Rt48KjqdAqb6o7Fi1X-4g1c7a9ronmoEuKFVHRE0k-2UOA&_nc_zt=14&_nc_ht=scontent-ord5-1.xx&_nc_gid=gsoqteP1KA6P7obCLlyteA&oh=00_AYGz-Yh2XCWtPS3IKnCPb6XsSVTvzeOl0J8CfPgZbVBXeg&oe=67E3B991">Paper</a>/
            <p>A new state-of-the-art, fast pipeline for text-to-3D asset generation </p>
          </td>
        </tr>

        <tr onmouseout="lightplane_stop()" onmouseover="lightplane_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='lightplane_image'>
              </div>
              <img src='data/image/co3d.gif' width="200">
              </div>
            <script type="text/javascript">
              function lightplane_start() {
                document.getElementById('lightplane_image').style.opacity = "1";
              }

              function lightplane_stop() {
                document.getElementById('lightplane_image').style.opacity = "0";
              }
              lightplane_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>Lightplane: Highly-Scalable Components for Neural 3D Fields</papertitle>
            </a>
            <br>
            <strong> Ang Cao</strong>,
            <a href="https://web.eecs.umich.edu/~justincj/"> Justin Johnson</a>,
            <a href="https://www.robots.ox.ac.uk/~vedaldi/"> Andrea Vedaldi</a>,
            <a href="https://d-novotny.github.io/"> David Novotny</a>
            <br>
            <em>3DV, </em> 2025
            <br>
            <a href="https://lightplane.github.io/">project page</a>/
            <a href="https://ArXiv.org/abs/2404.19760">ArXiv</a>/
            <a href="https://lightplane.github.io/docs/">Docs</a>/
            <a href="https://github.com/facebookresearch/lightplane">code</a>
            <p></p>
            <p>We investigate <b>"flashattention"</b> for NeRF: we present <b>Lightplane Splatter</b> and <b>Lightplane Renderer</b>, a pair of <b>extremely memory efficient</b> modules which can lift 2D images to 3D and render from theoretically any 3D hash representation  with <b>4-5 orders of magnitude</b> memory savings.
            We show its usage in a set of 3D recon and generation tasks.</p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='vilp_image'>
              </div>
              <img src='data/image/dream4d.gif' width="200">
              </div>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>DreamGaussian4D: Generative 4D Gaussian Splatting</papertitle>
            </a>
            <br>
            <a href="https://jiawei-ren.github.io">Jiawei Ren*</a>,
            <a href="https://github.com/paul007pl"> Liang Pan*</a>,
            <a href="https://me.kiui.moe/">Jiaxiang Tang </a>,
            <a href="https://www.linkedin.com/in/helenchizhang/?originalSubdomain=sg"> Chi Zhang</a>,
            <strong> Ang Cao</strong>,
            <a href="https://www.cis.pku.edu.cn/info/1177/1378.htm">Gang Zeng</a>,
            <a href="https://liuziwei7.github.io/">Ziwei Liu</a>,
            <br>
            <em>ArXiv, </em> 2023
            <a href="https://arxiv.org/abs/2312.17142">ArXiv</a>/
            <a href="https://jiawei-ren.github.io/projects/dreamgaussian4d/">Website</a>/
            <a href="https://github.com/jiawei-ren/dreamgaussian4d">Code</a>/
            <p>We do 4D generation with Gaussian Splatting by distilling motions from video diffusion models.</p>
          </td>
        </tr>


        <tr onmouseout="text2room_stop()" onmouseover="text2room_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='text2room_image'>
              </div>
              <img src='data/image/text2room.gif' width="200">
              </div>
            <script type="text/javascript">
              function text2room_start() {
                document.getElementById('text2room_image').style.opacity = "1";
              }

              function text2room_stop() {
                document.getElementById('text2room_image').style.opacity = "0";
              }
              hexplane_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models</papertitle>
            </a>
            <br>
            <a href="https://niessnerlab.org/members/lukas_hoellein/profile.html">Lukas Höllein *</a>,
            <strong> Ang Cao *</strong>,
            <a href="https://andrewowens.com/"> Andrew Owens</a>,
            <a href="https://web.eecs.umich.edu/~justincj"> Justin Johnson</a>,
            <a href="https://niessnerlab.org/members/matthias_niessner/profile.html"> Matthias Nießner</a>
            <br>
            <em>ICCV, <span style="color:red"> Oral  </span>, </em> 2023
            <br>
            <a href="https://lukashoel.github.io/text-to-room/">project page</a>/
            <a href="https://ArXiv.org/abs/2303.11989">ArXiv</a>/
            <a href="https://www.youtube.com/watch?v=fjRnFL91EZc&feature=youtu.be&ab_channel=MatthiasNiessner">video</a>/
            <a href="https://github.com/lukasHoel/text2room">code</a>
            <p></p>
            <p>We generate meshes of full 3D rooms using text-to-image models.</p>
          </td>
        </tr>

        <tr onmouseout="hexplane_stop()" onmouseover="hexplane_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='hexplane_image'>
              </div>
              <img src='data/image/HexPlane.gif' width="200">
              </div>
            <script type="text/javascript">
              function hexplane_start() {
                document.getElementById('hexplane_image').style.opacity = "1";
              }

              function hexplane_stop() {
                document.getElementById('hexplane_image').style.opacity = "0";
              }
              hexplane_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>HexPlane: A Fast Representation for Dynamic Scenes</papertitle>
            </a>
            <br>
            <strong>Ang Cao</strong>,
            <a href="https://web.eecs.umich.edu/~justincj">Justin Johnson</a>
            <br>
            <em>CVPR</em>, 2023
            <br>
            <a href="https://caoang327.github.io/HexPlane/">project page</a>/
            <a href="https://ArXiv.org/abs/2301.09632">ArXiv</a>/
            <a href="">video</a>/
            <a href="https://github.com/Caoang327/HexPlane">code</a>
            <p></p>
            <p>An elegant representation for dynamic 3D scenes using six feature planes.</p>
          </td>
        </tr>

        <tr onmouseout="fwd_stop()" onmouseover="fwd_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='fwd_image'>
              </div>
              <img src='data/image/FWD_model.png' width="200">
              </div>
            <script type="text/javascript">
              function fwd_start() {
                document.getElementById('fwd_image').style.opacity = "1";
              }

              function fwd_stop() {
                document.getElementById('fwd_image').style.opacity = "0";
              }
              fwd_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:sub">
            <a href="">
              <papertitle>FWD: Real-time Novel View Synthesis with Forward Warping and Depth</papertitle>
            </a>
            <br>
            <strong>Ang Cao</strong>,
            <a href="https://crockwell.github.io/">Chris Rockwell</a>, 
            <a href="https://web.eecs.umich.edu/~justincj">Justin Johnson</a>
            <br>
            <em>CVPR</em>, 2022  
            <br>
            <a href="https://caoang327.github.io/FWD/">project page</a> / 
            <a href="https://ArXiv.org/pdf/2206.08355.pdf">ArXiv</a> / 
            <a href="https://www.youtube.com/watch?v=d7m1fJ1LcAY&ab_channel=AngCao">video</a> /
            <a href="https://github.com/Caoang327/fwd_code">code</a> / 
            <p></p>
            <p>We show point rasterization can be really fast for sparse view novel view synthesis.</p>
          </td>
        </tr>

        <tr onmouseout="visdet_stop()" onmouseover="visdet_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='visdet_image'>
              </div>
              <img src='data/image/visdet.png' width="200">
              </div>
            <script type="text/javascript">
              function visdet_start() {
                document.getElementById('visdet_image').style.opacity = "1";
              }

              function visdet_stop() {
                document.getElementById('visdet_image').style.opacity = "0";
              }
              visdet_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:baseline">
            <a href="">
              <papertitle>Inverting and Understanding Object Detectors</papertitle>
            </a>
            <br>
            <strong>Ang Cao</strong>,
            <a href="https://web.eecs.umich.edu/~justincj">Justin Johnson</a>
            <br>
            <em>Tech report</em>, 2021 
            <br>
            <a href="https://ArXiv.org/pdf/2106.13933.pdf">ArXiv</a> / 
            <a href="https://github.com/Caoang327/vis_det">code</a> / 
            <p></p>
            <p> Revealing intriguing properties of detectors by applying our layout inversion technique.</p>
          </td>
        </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr></tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Teaching Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="visdet_stop()" onmouseover="visdet_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='visdet_image'>
                </div>
                <img src='data/image/graphics.png' width="200">
                </div>
              <script type="text/javascript">
                function visdet_start() {
                  document.getElementById('visdet_image').style.opacity = "1";
                }
  
                function visdet_stop() {
                  document.getElementById('visdet_image').style.opacity = "0";
                }
                visdet_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:baseline">
              <a href="https://um-graphics.github.io/">
                <papertitle>EECS 498/598: Computer Graphics and Generative Models (Fall 2024)</papertitle>
              </a>
              <br>
              <br>
              <p> Teaching assistant (GSI/Head TA), working with <a href="https://jjparkcv.github.io/">JJ Park</a> </p>
            </td>
          </tr>
        </tbody></table>

<!-- 
        <tr onmouseout="bpgan_stop()" onmouseover="bpgan_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='visdet_image'>
              </div>
              <img src='data/image/bpgan.png' width="200">
              </div>
            <script type="text/javascript">
              function bpgan_start() {
                document.getElementById('bpgan_image').style.opacity = "1";
              }

              function visdet_stop() {
                document.getElementById('bpgan_image').style.opacity = "0";
              }
              visdet_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:baseline">
            <a href="">
              <papertitle>Unified Signal Compression Using Generative Adverserial Networks</papertitle>
            </a>
            <br>  Bowen Liu *, 
            <strong>Ang Cao * </strong>, 
            <a href="https://kim.engin.umich.edu/"> Hun-Seok Kim</a>
            <br>
            <em>International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), <b>Oral</b></em>, 2020
            <br>
            <a href="https://ArXiv.org/abs/1912.03734">ArXiv</a> / 
            <a href="https://github.com/Caoang327/GAN_Compression">code</a> / 
            <p></p>
            <p> Proposing an ADMM (alternating direction method of multipliers) to compress the signal into quantized latent vectors.
            </p>
          </td>
        </tr> -->

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Service</heading>
          </td>
        </tr>
      </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br> Huge thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the awesome <a href="https://github.com/jonbarron/jonbarron_website">template</a>.
              <p style="text-align:right;font-size:small;">
            </td>
          </tr>
        </tbody></table>


</body>

</html>
